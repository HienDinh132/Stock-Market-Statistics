{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847028b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tkinter import * \n",
    "import ttkbootstrap as tb\n",
    "from tkinter import messagebox, ttk, filedialog, colorchooser\n",
    "from PIL import ImageTk, Image\n",
    "import os\n",
    "import pathlib\n",
    "import datetime as dt\n",
    "import csv \n",
    "import pyodbc\n",
    "import urllib\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909f8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'ADMIN-PC'\n",
    "database = 'HSX_thong_ke'\n",
    "\n",
    "quoted = urllib.parse.quote_plus('Driver={SQL Server};'\n",
    "                                 'Server='+server+';'\n",
    "                                 'Database='+database+';')\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server='+server+';'\n",
    "                      'Database='+database+';'\n",
    "                      'Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "911c030c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mã</th>\n",
       "      <th>None 202107</th>\n",
       "      <th>None 202212</th>\n",
       "      <th>Vn30 202107</th>\n",
       "      <th>Vn30 202212</th>\n",
       "      <th>VnMid 202107</th>\n",
       "      <th>VnMid 202212</th>\n",
       "      <th>VnSmall 202107</th>\n",
       "      <th>VnSmall 202212</th>\n",
       "      <th>ETL_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202107</td>\n",
       "      <td>202212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAM</td>\n",
       "      <td>202107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202212</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAT</td>\n",
       "      <td>202107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202212</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABR</td>\n",
       "      <td>202107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202212</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202107</td>\n",
       "      <td>202212</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>VSI</td>\n",
       "      <td>0</td>\n",
       "      <td>202212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202107</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>VTB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202107</td>\n",
       "      <td>202212</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>VTO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202107</td>\n",
       "      <td>202212</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>YBM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202107</td>\n",
       "      <td>202212</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>YEG</td>\n",
       "      <td>202107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202212</td>\n",
       "      <td>2025-09-05 07:34:28.175371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mã   None 202107  None 202212  Vn30 202107  Vn30 202212  VnMid 202107  \\\n",
       "0    AAA            0            0            0            0        202107   \n",
       "1    AAM       202107            0            0            0             0   \n",
       "2    AAT       202107            0            0            0             0   \n",
       "3    ABR       202107            0            0            0             0   \n",
       "4    ABS            0            0            0            0             0   \n",
       "..   ...          ...          ...          ...          ...           ...   \n",
       "441  VSI            0       202212            0            0             0   \n",
       "442  VTB            0            0            0            0             0   \n",
       "443  VTO            0            0            0            0             0   \n",
       "444  YBM            0            0            0            0             0   \n",
       "445  YEG       202107            0            0            0             0   \n",
       "\n",
       "     VnMid 202212  VnSmall 202107  VnSmall 202212                    ETL_date  \n",
       "0          202212               0               0  2025-09-05 07:34:28.175371  \n",
       "1               0               0          202212  2025-09-05 07:34:28.175371  \n",
       "2               0               0          202212  2025-09-05 07:34:28.175371  \n",
       "3               0               0          202212  2025-09-05 07:34:28.175371  \n",
       "4               0          202107          202212  2025-09-05 07:34:28.175371  \n",
       "..            ...             ...             ...                         ...  \n",
       "441             0          202107               0  2025-09-05 07:34:28.175371  \n",
       "442             0          202107          202212  2025-09-05 07:34:28.175371  \n",
       "443             0          202107          202212  2025-09-05 07:34:28.175371  \n",
       "444             0          202107          202212  2025-09-05 07:34:28.175371  \n",
       "445             0               0          202212  2025-09-05 07:34:28.175371  \n",
       "\n",
       "[446 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hsx_index = pd.read_csv('hsx_index.csv')\n",
    "df_hsx_index['ETL_date'] = str(dt.datetime.now())\n",
    "df_hsx_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef413037",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''if (OBJECT_ID('dim_hsx_index') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_hsx_index\n",
    "\t(\n",
    "\t\t[Ma_ck] varchar(10),\n",
    "\t\t[None_202107] int,\n",
    "        [None_202212] int,\n",
    "        [Vn30_202107] int,\n",
    "        [Vn30_202212] int,\n",
    "        [Vnmid_202107] int,\n",
    "        [Vnmid_202212] int,\n",
    "        [Vnsmall_202107] int,\n",
    "        [Vnsmall_202212] int,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_hsx_index.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_hsx_index.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_hsx_index.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_hsx_index')\n",
    "    cursor.executemany('''INSERT INTO dim_hsx_index Values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d1d3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GDP</th>\n",
       "      <th>ETL_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>1116680.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>1366899.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>1539114.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2010887.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1188207.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1382995.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>1593586.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2121415.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>1915368.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2050431.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>1986949.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2399005.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>2132796.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>2292012.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2373152.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2669131.0</td>\n",
       "      <td>2025-09-05 07:34:28.839982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        GDP                    ETL_date\n",
       "0  2019-03-31  1116680.0  2025-09-05 07:34:28.839982\n",
       "1  2019-06-30  1366899.0  2025-09-05 07:34:28.839982\n",
       "2  2019-09-30  1539114.0  2025-09-05 07:34:28.839982\n",
       "3  2019-12-31  2010887.0  2025-09-05 07:34:28.839982\n",
       "4  2020-03-31  1188207.0  2025-09-05 07:34:28.839982\n",
       "5  2020-06-30  1382995.0  2025-09-05 07:34:28.839982\n",
       "6  2020-09-30  1593586.0  2025-09-05 07:34:28.839982\n",
       "7  2020-12-31  2121415.0  2025-09-05 07:34:28.839982\n",
       "8  2021-03-31  1915368.0  2025-09-05 07:34:28.839982\n",
       "9  2021-06-30  2050431.0  2025-09-05 07:34:28.839982\n",
       "10 2021-09-30  1986949.0  2025-09-05 07:34:28.839982\n",
       "11 2021-12-31  2399005.0  2025-09-05 07:34:28.839982\n",
       "12 2022-03-31  2132796.0  2025-09-05 07:34:28.839982\n",
       "13 2022-06-30  2292012.0  2025-09-05 07:34:28.839982\n",
       "14 2022-09-30  2373152.0  2025-09-05 07:34:28.839982\n",
       "15 2022-12-31  2669131.0  2025-09-05 07:34:28.839982"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gdp = pd.read_excel('gdp.xlsx')\n",
    "df_gdp['ETL_date'] = str(dt.datetime.now())\n",
    "df_gdp['GDP'] = df_gdp['GDP'].astype('float')\n",
    "df_gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927315cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''if (OBJECT_ID('fact_gdp') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_gdp\n",
    "\t(\n",
    "\t\t[Date] datetime2,\n",
    "\t\t[gdp_ty_vnd] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_gdp.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gdp.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gdp.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_gdp')\n",
    "    cursor.executemany('''INSERT INTO fact_gdp Values (?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c054d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_nam = [\"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "lst_thang = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n",
    "lst_path_text = []\n",
    "for i in lst_nam:\n",
    "    for j in lst_thang:\n",
    "        lst_path_text.append(f'D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\Market Update\\\\HSX\\\\Raw HSX\\\\Chi tiet giao dich theo loai NDT (VNI)\\\\{i}\\\\Chi tiet GDTLNDT {i}\\\\Thang {j}')\n",
    "lst_path_text = [pathlib.Path(i) for i in lst_path_text]\n",
    "lst_path_text\n",
    "\n",
    "files = []\n",
    "for path in lst_path_text:\n",
    "    for direc in path.iterdir():\n",
    "        file = direc.stem\n",
    "        if not file.startswith(\"G\"):\n",
    "            files.append(direc)\n",
    "\n",
    "lst_df = []\n",
    "for path in files:\n",
    "    date = path.stem\n",
    "\n",
    "    skiprows = [i for i in range(0,11)]\n",
    "    df = pd.read_excel(path, skiprows=lambda x: x in skiprows, sheet_name='ExportData')\n",
    "    df = df.iloc[:, :-1]\n",
    "    lst_phan_nhom = ['Cá nhân trong nước', 'Cá nhân nước ngoài', 'Tổ chức trong nước', 'Tổ chức nước ngoài']\n",
    "    lst_phan_nhom = [[i]*6 for i in lst_phan_nhom]\n",
    "    lst_phan_nhom = lst_phan_nhom[0] + lst_phan_nhom[1] + lst_phan_nhom[2] + lst_phan_nhom[3]\n",
    "\n",
    "    lst_abc_phan_loai = list(df.iloc[0].values[1:][0:6])\n",
    "    lst_abc_phan_loai = lst_abc_phan_loai * 4\n",
    "\n",
    "    lst_column1 = list(zip(lst_phan_nhom, lst_abc_phan_loai))\n",
    "    lst_column2 = []\n",
    "    for i in lst_column1:\n",
    "        lst_column2.append(i[0] + \" - \" + i[1])\n",
    "\n",
    "    lst_column2.insert(0, \"Ma_ck\")\n",
    "    df.columns = lst_column2\n",
    "    df = df.iloc[4:]\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"Ngay\"] = dt.datetime.strptime(date, \"%m.%d.%Y\")\n",
    "    lst_df.append(df)\n",
    "df_new = pd.DataFrame(pd.concat(lst_df))\n",
    "df_new = df_new[df_new[\"Cá nhân trong nước - Khối lượng mua (CP)\"].isnull() == False]\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new.head(5)\n",
    "\n",
    "###########################################\n",
    "\n",
    "df_gtm = df_new[['Ma_ck', 'Ngay', 'Cá nhân trong nước - Giá trị mua  (Nghìn VNĐ)', 'Cá nhân nước ngoài - Giá trị mua  (Nghìn VNĐ)',\n",
    "               'Tổ chức trong nước - Giá trị mua  (Nghìn VNĐ)', 'Tổ chức nước ngoài - Giá trị mua  (Nghìn VNĐ)']].copy()\n",
    "df_gtm['Cá nhân trong nước - Giá trị mua  (Nghìn VNĐ)'] = df_gtm['Cá nhân trong nước - Giá trị mua  (Nghìn VNĐ)'].astype('float')\n",
    "df_gtm['Cá nhân nước ngoài - Giá trị mua  (Nghìn VNĐ)'] = df_gtm['Cá nhân nước ngoài - Giá trị mua  (Nghìn VNĐ)'].astype('float')\n",
    "df_gtm['Tổ chức trong nước - Giá trị mua  (Nghìn VNĐ)'] = df_gtm['Tổ chức trong nước - Giá trị mua  (Nghìn VNĐ)'].astype('float')\n",
    "df_gtm['Tổ chức nước ngoài - Giá trị mua  (Nghìn VNĐ)'] = df_gtm['Tổ chức nước ngoài - Giá trị mua  (Nghìn VNĐ)'].astype('float')\n",
    "df_gtm = df_gtm.melt(id_vars=[\"Ma_ck\", \"Ngay\"], var_name=\"Phan_loai\", value_name=\"Value\")\n",
    "df_gtm[\"index\"] = df_gtm[\"Phan_loai\"].str.index('-')\n",
    "df_gtm[\"Phan_loai\"] = df_gtm.apply(lambda row: row[\"Phan_loai\"][:row[\"index\"]], axis=1)\n",
    "df_gtm[\"Phan_loai\"] = df_gtm[\"Phan_loai\"].str.strip()\n",
    "df_gtm = df_gtm[[\"Ma_ck\", \"Ngay\", \"Phan_loai\", \"Value\"]]\n",
    "df_gtm['ETL_date'] = str(dt.datetime.now())\n",
    "\n",
    "######################################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_gtm') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_gtm\n",
    "\t(\n",
    "\t\t[Ma_ck] varchar(10),\n",
    "\t\t[Ngay] datetime2,\n",
    "        [Phan_loai] nvarchar(255),\n",
    "        [Value_nghin_vnd] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "##################################################\n",
    "\n",
    "df_gtm.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gtm.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gtm.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_gtm')\n",
    "    cursor.executemany('''INSERT INTO fact_gtm Values (?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "##################################################\n",
    "\n",
    "df_klm = df_new[['Ma_ck', 'Ngay', 'Cá nhân trong nước - Khối lượng mua (CP)', 'Cá nhân nước ngoài - Khối lượng mua (CP)', 'Tổ chức trong nước - Khối lượng mua (CP)',\n",
    "                 'Tổ chức nước ngoài - Khối lượng mua (CP)']].copy()\n",
    "df_klm['Cá nhân trong nước - Khối lượng mua (CP)'] = df_klm['Cá nhân trong nước - Khối lượng mua (CP)'].astype('float')\n",
    "df_klm['Cá nhân nước ngoài - Khối lượng mua (CP)'] = df_klm['Cá nhân nước ngoài - Khối lượng mua (CP)'].astype('float')\n",
    "df_klm['Tổ chức trong nước - Khối lượng mua (CP)'] = df_klm['Tổ chức trong nước - Khối lượng mua (CP)'].astype('float')\n",
    "df_klm['Tổ chức nước ngoài - Khối lượng mua (CP)'] = df_klm['Tổ chức nước ngoài - Khối lượng mua (CP)'].astype('float')\n",
    "df_klm = df_klm.melt(id_vars=[\"Ma_ck\", \"Ngay\"], var_name=\"Phan_loai\", value_name=\"Value\")\n",
    "df_klm[\"index\"] = df_klm[\"Phan_loai\"].str.index('-')\n",
    "df_klm[\"Phan_loai\"] = df_klm.apply(lambda row: row[\"Phan_loai\"][:row[\"index\"]], axis=1)\n",
    "df_klm[\"Phan_loai\"] = df_klm[\"Phan_loai\"].str.strip()\n",
    "df_klm = df_klm[[\"Ma_ck\", \"Ngay\", \"Phan_loai\", \"Value\"]]\n",
    "df_klm['ETL_date'] = str(dt.datetime.now())\n",
    "df_klm\n",
    "\n",
    "########################################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_klm') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_klm\n",
    "\t(\n",
    "\t\t[Ma_ck] varchar(10),\n",
    "\t\t[Ngay] datetime2,\n",
    "        [Phan_loai] nvarchar(255),\n",
    "        [Value_cp] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "##########################################################\n",
    "\n",
    "df_klm.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_klm.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_klm.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_klm')\n",
    "    cursor.executemany(''' INSERT INTO fact_klm Values (?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "###########################################################\n",
    "\n",
    "df_gtb = df_new[['Ma_ck', 'Ngay', 'Cá nhân trong nước - Giá trị Bán (Nghìn VNĐ)', 'Cá nhân nước ngoài - Giá trị Bán (Nghìn VNĐ)', 'Tổ chức trong nước - Giá trị Bán (Nghìn VNĐ)',\n",
    "                 'Tổ chức nước ngoài - Giá trị Bán (Nghìn VNĐ)']].copy()\n",
    "df_gtb['Cá nhân trong nước - Giá trị Bán (Nghìn VNĐ)'] = df_gtb['Cá nhân trong nước - Giá trị Bán (Nghìn VNĐ)'].astype('float')\n",
    "df_gtb['Cá nhân nước ngoài - Giá trị Bán (Nghìn VNĐ)'] = df_gtb['Cá nhân nước ngoài - Giá trị Bán (Nghìn VNĐ)'].astype('float')\n",
    "df_gtb['Tổ chức trong nước - Giá trị Bán (Nghìn VNĐ)'] = df_gtb['Tổ chức trong nước - Giá trị Bán (Nghìn VNĐ)'].astype('float')\n",
    "df_gtb['Tổ chức nước ngoài - Giá trị Bán (Nghìn VNĐ)'] = df_gtb['Tổ chức nước ngoài - Giá trị Bán (Nghìn VNĐ)'].astype('float')\n",
    "\n",
    "df_gtb = df_gtb.melt(id_vars=[\"Ma_ck\", \"Ngay\"], var_name=\"Phan_loai\", value_name=\"Value\")\n",
    "df_gtb[\"index\"] = df_gtb[\"Phan_loai\"].str.index('-')\n",
    "df_gtb[\"Phan_loai\"] = df_gtb.apply(lambda row: row[\"Phan_loai\"][:row[\"index\"]], axis=1)\n",
    "df_gtb[\"Phan_loai\"] = df_gtb[\"Phan_loai\"].str.strip()\n",
    "df_gtb = df_gtb[[\"Ma_ck\", \"Ngay\", \"Phan_loai\", \"Value\"]]\n",
    "df_gtb['ETL_date'] = str(dt.datetime.now())\n",
    "df_gtb\n",
    "\n",
    "################################################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_gtb') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_gtb\n",
    "\t(\n",
    "\t\t[Ma_ck] varchar(10),\n",
    "\t\t[Ngay] datetime2,\n",
    "        [Phan_loai] nvarchar(255),\n",
    "        [Value_nghin_vnd] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "df_gtb.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gtb.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gtb.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_gtb')\n",
    "    cursor.executemany(''' INSERT INTO fact_gtb Values (?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "df_klb = df_new[['Ma_ck', 'Ngay', 'Cá nhân trong nước - Khối lượng Bán (CP)', 'Cá nhân nước ngoài - Khối lượng Bán (CP)', 'Tổ chức trong nước - Khối lượng Bán (CP)',\n",
    "                  'Tổ chức nước ngoài - Khối lượng Bán (CP)']].copy()\n",
    "df_klb['Cá nhân trong nước - Khối lượng Bán (CP)'] = df_klb['Cá nhân trong nước - Khối lượng Bán (CP)'].astype('float')\n",
    "df_klb['Cá nhân nước ngoài - Khối lượng Bán (CP)'] = df_klb['Cá nhân nước ngoài - Khối lượng Bán (CP)'].astype('float')\n",
    "df_klb['Tổ chức trong nước - Khối lượng Bán (CP)'] = df_klb['Tổ chức trong nước - Khối lượng Bán (CP)'].astype('float')\n",
    "df_klb['Tổ chức nước ngoài - Khối lượng Bán (CP)'] = df_klb['Tổ chức nước ngoài - Khối lượng Bán (CP)'].astype('float')\n",
    "\n",
    "df_klb = df_klb.melt(id_vars=[\"Ma_ck\", \"Ngay\"], var_name=\"Phan_loai\", value_name=\"Value\")\n",
    "df_klb[\"index\"] = df_klb[\"Phan_loai\"].str.index('-')\n",
    "df_klb[\"Phan_loai\"] = df_klb.apply(lambda row: row[\"Phan_loai\"][:row[\"index\"]], axis=1)\n",
    "df_klb[\"Phan_loai\"] = df_klb[\"Phan_loai\"].str.strip()\n",
    "df_klb = df_klb[[\"Ma_ck\", \"Ngay\", \"Phan_loai\", \"Value\"]]\n",
    "df_klb['ETL_date'] = str(dt.datetime.now())\n",
    "df_klb\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_klb') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_klb\n",
    "\t(\n",
    "\t\t[Ma_ck] varchar(10),\n",
    "\t\t[Ngay] datetime2,\n",
    "        [Phan_loai] nvarchar(255),\n",
    "        [Value_cp] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "######################################\n",
    "\n",
    "df_klb.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_klb.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_klb.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_klb')\n",
    "    cursor.executemany(''' INSERT INTO fact_klb Values (?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "#########################################\n",
    "\n",
    "df_gtr = df_new[['Ma_ck', 'Ngay', 'Cá nhân trong nước - Giá trị ròng (Nghìn VNĐ)', 'Cá nhân nước ngoài - Giá trị ròng (Nghìn VNĐ)', \n",
    "                  'Tổ chức trong nước - Giá trị ròng (Nghìn VNĐ)', 'Tổ chức nước ngoài - Giá trị ròng (Nghìn VNĐ)']].copy()\n",
    "\n",
    "df_gtr['Cá nhân trong nước - Giá trị ròng (Nghìn VNĐ)'] = df_gtr['Cá nhân trong nước - Giá trị ròng (Nghìn VNĐ)'].astype('float')\n",
    "df_gtr['Cá nhân nước ngoài - Giá trị ròng (Nghìn VNĐ)'] = df_gtr['Cá nhân nước ngoài - Giá trị ròng (Nghìn VNĐ)'].astype('float')\n",
    "df_gtr['Tổ chức trong nước - Giá trị ròng (Nghìn VNĐ)'] = df_gtr['Tổ chức trong nước - Giá trị ròng (Nghìn VNĐ)'].astype('float')\n",
    "df_gtr['Tổ chức nước ngoài - Giá trị ròng (Nghìn VNĐ)'] = df_gtr['Tổ chức nước ngoài - Giá trị ròng (Nghìn VNĐ)'].astype('float')\n",
    "\n",
    "df_gtr = df_gtr.melt(id_vars=[\"Ma_ck\", \"Ngay\"], var_name=\"Phan_loai\", value_name=\"Value\")\n",
    "df_gtr[\"index\"] = df_gtr[\"Phan_loai\"].str.index('-')\n",
    "df_gtr[\"Phan_loai\"] = df_gtr.apply(lambda row: row[\"Phan_loai\"][:row[\"index\"]], axis=1)\n",
    "df_gtr[\"Phan_loai\"] = df_gtr[\"Phan_loai\"].str.strip()\n",
    "df_gtr = df_gtr[[\"Ma_ck\", \"Ngay\", \"Phan_loai\", \"Value\"]]\n",
    "df_gtr['ETL_date'] = str(dt.datetime.now())\n",
    "df_gtr\n",
    "\n",
    "############################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_gtr') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_gtr\n",
    "\t(\n",
    "\t\t[Ma_ck] varchar(10),\n",
    "\t\t[Ngay] datetime2,\n",
    "        [Phan_loai] nvarchar(255),\n",
    "        [Value_nghin_vnd] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "#############################################3\n",
    "\n",
    "df_gtr.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gtr.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gtr.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_gtr')\n",
    "    cursor.executemany(''' INSERT INTO fact_gtr Values (?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "###############################\n",
    "\n",
    "df_klr = df_new[['Ma_ck', 'Ngay', 'Cá nhân trong nước - Khối lượng ròng (CP)', 'Cá nhân nước ngoài - Khối lượng ròng (CP)', 'Tổ chức trong nước - Khối lượng ròng (CP)',\n",
    "                  'Tổ chức nước ngoài - Khối lượng ròng (CP)']].copy()\n",
    "df_klr['Cá nhân trong nước - Khối lượng ròng (CP)'] = df_klr['Cá nhân trong nước - Khối lượng ròng (CP)'].astype('float')\n",
    "df_klr['Cá nhân nước ngoài - Khối lượng ròng (CP)'] = df_klr['Cá nhân nước ngoài - Khối lượng ròng (CP)'].astype('float')\n",
    "df_klr['Tổ chức trong nước - Khối lượng ròng (CP)'] = df_klr['Tổ chức trong nước - Khối lượng ròng (CP)'].astype('float')\n",
    "df_klr['Tổ chức nước ngoài - Khối lượng ròng (CP)'] = df_klr['Tổ chức nước ngoài - Khối lượng ròng (CP)'].astype('float')\n",
    "\n",
    "df_klr = df_klr.melt(id_vars=[\"Ma_ck\", \"Ngay\"], var_name=\"Phan_loai\", value_name=\"Value\")\n",
    "df_klr[\"index\"] = df_klr[\"Phan_loai\"].str.index('-')\n",
    "df_klr[\"Phan_loai\"] = df_klr.apply(lambda row: row[\"Phan_loai\"][:row[\"index\"]], axis=1)\n",
    "df_klr[\"Phan_loai\"] = df_klr[\"Phan_loai\"].str.strip()\n",
    "df_klr = df_klr[[\"Ma_ck\", \"Ngay\", \"Phan_loai\", \"Value\"]]\n",
    "df_klr['ETL_date'] = str(dt.datetime.now())\n",
    "df_klr\n",
    "\n",
    "###################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_klr') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_klr\n",
    "\t(\n",
    "\t\t[Ma_ck] varchar(10),\n",
    "\t\t[Ngay] datetime2,\n",
    "        [Phan_loai] nvarchar(255),\n",
    "        [Value_cp] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "####################################\n",
    "\n",
    "df_klr.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_klr.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_klr.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_klr')\n",
    "    cursor.executemany(''' INSERT INTO fact_klr Values (?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581c0b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_data_2 \n",
    "\n",
    "lst_nam = [\"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "lst_thang = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n",
    "lst_path_text = []\n",
    "for i in lst_nam:\n",
    "    for j in lst_thang:\n",
    "        lst_path_text.append(f'D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\Market Update\\\\HSX\\\\Raw HSX\\\\Chi tiet Tu doanh\\\\{i}\\\\Thang {j}')\n",
    "lst_path_text = [pathlib.Path(i) for i in lst_path_text]\n",
    "\n",
    "files = []\n",
    "for path in lst_path_text:\n",
    "    for direc in path.iterdir():\n",
    "        file = direc.stem\n",
    "        if not file.startswith(\"G\"):\n",
    "            files.append(direc)\n",
    "\n",
    "lst_df = []\n",
    "for path in files:\n",
    "    skiprows = [i for i in range(0,11)]\n",
    "    date_name = path.stem\n",
    "    df = pd.read_excel(path, sheet_name='ExportData', skiprows=lambda x: x in skiprows)\n",
    "    df = df.iloc[:, :-2]\n",
    "    df = df.iloc[2:]\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"Ngay\"] = dt.datetime.strptime(date_name, \"%m.%d.%Y\")\n",
    "    lst_df.append(df)\n",
    "\n",
    "df_new = pd.DataFrame(pd.concat(lst_df))\n",
    "df_new = df_new[(df_new[\"Khối lượng mua\"].isnull() == False) & (df_new[\"Khối lượng bán\"].isnull() == False)]\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new[\"phan_loai\"] = \"Tu doanh\"\n",
    "df_new[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_new.head(5)\n",
    "\n",
    "###########################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_tu_doanh') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_tu_doanh\n",
    "\t(\n",
    "\t\t[Ma_ck] varchar(10),\n",
    "        [Khoi_luong_mua_cp] float,\n",
    "        [Khoi_luong_ban_cp] float,\n",
    "        [Gia_tri_mua_trieu_vnd] float,\n",
    "        [Gia_tri_ban_trieu_vnd] float,\n",
    "        [Gia_tri_rong_trieu_vnd] float,\n",
    "        [Khoi_luong_rong_cp] float,\n",
    "\t\t[Ngay] datetime2,\n",
    "        [Phan_loai] nvarchar(20),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "###############################\n",
    "\n",
    "df_new.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_tu_doanh.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_tu_doanh.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_tu_doanh')\n",
    "    cursor.executemany(''' INSERT INTO fact_tu_doanh Values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "df_tu_doanh = df_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d40f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_data_4\n",
    "\n",
    "path_text = f'D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\Market Update\\\\HSX\\\\Raw HSX\\\\GDTT\\\\GDTT'\n",
    "path = pathlib.Path(path_text)\n",
    "\n",
    "###################\n",
    "\n",
    "lst_file = []\n",
    "for direc in path.iterdir():\n",
    "    for i in direc.iterdir():\n",
    "        k = i.stem\n",
    "        if not k.startswith(\"G\"):\n",
    "            lst_file.append(i)\n",
    "\n",
    "########################\n",
    "\n",
    "lst_df = []\n",
    "for path in lst_file:\n",
    "    skiprows = [i for i in range(0,7)]\n",
    "    df = pd.read_excel(path, sheet_name='ExportData', skiprows=lambda x: x in skiprows)\n",
    "    df = df.iloc[1:]\n",
    "    df.columns = [\"Ma_CK\", \"Ten\", \"Ngay_GD\", \"Gia_tri_thoa_thuan\"]\n",
    "    lst_df.append(df)\n",
    "df_new = pd.DataFrame(pd.concat(lst_df))\n",
    "df_new = pd.DataFrame(pd.concat(lst_df))\n",
    "df_new = df_new[(df_new[\"Ten\"].isnull() == False) & (df_new[\"Ngay_GD\"].isnull() == False)]\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_thoa_thuan = df_new.copy()\n",
    "\n",
    "###########################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_thoa_thuan') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_thoa_thuan\n",
    "\t(\n",
    "        [Ma_ck] varchar(10),\n",
    "        [Ten] nvarchar(100),\n",
    "        [Ngay] datetime2,\n",
    "        [Gia_tri_thoa_thuan_vnd] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "#############################\n",
    "\n",
    "df_new.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_thoa_thuan.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_thoa_thuan.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_thoa_thuan')\n",
    "    cursor.executemany(''' INSERT INTO fact_thoa_thuan Values (?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6889d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_data_5\n",
    "\n",
    "df = pd.read_excel(\"Market HSX.xlsm\", sheet_name = [\"Khoi luong giao dich KL (xoay)\", \"Gia tri giao dich KL (xoay)\", \"So luong CP luu hanh (quy doi)\", \"Von hoa\"])\n",
    "\n",
    "#########################\n",
    "\n",
    "df_klgdkl = df[\"Khoi luong giao dich KL (xoay)\"]\n",
    "lst_column = df_klgdkl.columns\n",
    "lst_column = lst_column[1:]\n",
    "lst_column_new = []\n",
    "for i in lst_column:\n",
    "    k = i.index(\" \")\n",
    "    ck = i[:k]\n",
    "    lst_column_new.append(ck)\n",
    "lst_column_new.insert(0, \"Date\")\n",
    "df_klgdkl.columns = lst_column_new\n",
    "df_klgdkl = df_klgdkl.melt(id_vars=[\"Date\"], var_name=\"Ma_CK\", value_name=\"KLGDKL\")\n",
    "df_klgdkl[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_klgdkl.head(2)\n",
    "\n",
    "###########################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_khoi_luong_gd_khop_lenh') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_khoi_luong_gd_khop_lenh\n",
    "\t(\n",
    "        [Ngay] datetime2,\n",
    "        [Ma_ck] varchar(10),\n",
    "        [KLGDKL_cp] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "###########################\n",
    "\n",
    "df_klgdkl.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_khoi_luong_gd_khop_lenh.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_khoi_luong_gd_khop_lenh.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_khoi_luong_gd_khop_lenh')\n",
    "    cursor.executemany(''' INSERT INTO fact_khoi_luong_gd_khop_lenh Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "#########################\n",
    "\n",
    "df_gtgdkl = df[\"Gia tri giao dich KL (xoay)\"]\n",
    "lst_column = df_gtgdkl.columns\n",
    "lst_column = lst_column[1:]\n",
    "lst_column_new = []\n",
    "for i in lst_column:\n",
    "    k = i.index(\" \")\n",
    "    ck = i[:k]\n",
    "    lst_column_new.append(ck)\n",
    "lst_column_new.insert(0, \"Date\")\n",
    "df_gtgdkl.columns = lst_column_new\n",
    "df_gtgdkl = df_gtgdkl.melt(id_vars=[\"Date\"], var_name=\"Ma_CK\", value_name=\"GTGDKL\")\n",
    "df_gtgdkl[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_gtgdkl\n",
    "\n",
    "############################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_gia_tri_gd_khop_lenh') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_gia_tri_gd_khop_lenh\n",
    "\t(\n",
    "        [Ngay] datetime2,\n",
    "        [Ma_ck] varchar(10),\n",
    "        [GTGDKL_vnd] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "####################################\n",
    "\n",
    "df_gtgdkl.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gia_tri_gd_khop_lenh.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gia_tri_gd_khop_lenh.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_gia_tri_gd_khop_lenh')\n",
    "    cursor.executemany(''' INSERT INTO fact_gia_tri_gd_khop_lenh Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "###################################\n",
    "\n",
    "df_slcplh = df[\"So luong CP luu hanh (quy doi)\"]\n",
    "lst_column = df_slcplh.columns\n",
    "lst_column = lst_column[1:]\n",
    "lst_column_new = []\n",
    "for i in lst_column:\n",
    "    k = i.index(\" \")\n",
    "    ck = i[:k]\n",
    "    lst_column_new.append(ck)\n",
    "lst_column_new.insert(0, \"Date\")\n",
    "df_slcplh.columns = lst_column_new\n",
    "df_slcplh = df_slcplh.melt(id_vars=[\"Date\"], var_name=\"Ma_CK\", value_name=\"SLCPLH\")\n",
    "df_slcplh[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_slcplh\n",
    "\n",
    "###################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_so_luong_cp_luu_hanh') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_so_luong_cp_luu_hanh\n",
    "\t(\n",
    "        [Ngay] datetime2,\n",
    "        [Ma_ck] varchar(10),\n",
    "        [SLCPLH_cp] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "###################################\n",
    "\n",
    "df_slcplh.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_so_luong_cp_luu_hanh.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_so_luong_cp_luu_hanh.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_so_luong_cp_luu_hanh')\n",
    "    cursor.executemany(''' INSERT INTO fact_so_luong_cp_luu_hanh Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "##################################\n",
    "\n",
    "df_vh = df[\"Von hoa\"]\n",
    "lst_column = df_vh.columns\n",
    "lst_column = lst_column[1:]\n",
    "lst_column_new = []\n",
    "for i in lst_column:\n",
    "    k = i.index(\" \")\n",
    "    ck = i[:k]\n",
    "    lst_column_new.append(ck)\n",
    "lst_column_new.insert(0, \"Date\")\n",
    "df_vh.columns = lst_column_new\n",
    "df_vh = df_vh.melt(id_vars=[\"Date\"], var_name=\"Ma_CK\", value_name=\"Von hoa\")\n",
    "df_vh[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_vh\n",
    "\n",
    "##########################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_von_hoa') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_von_hoa\n",
    "\t(\n",
    "        [Ngay] datetime2,\n",
    "        [Ma_ck] varchar(10),\n",
    "        [Von_hoa_vnd] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "#################################\n",
    "\n",
    "df_vh.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_von_hoa.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_von_hoa.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_von_hoa')\n",
    "    cursor.executemany(''' INSERT INTO fact_von_hoa Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc892221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_join</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>2023-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>2023-06-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>2023-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>2023-06-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date_join\n",
       "0    2014-12-10\n",
       "1    2014-12-11\n",
       "2    2014-12-12\n",
       "3    2014-12-15\n",
       "4    2014-12-16\n",
       "...         ...\n",
       "2125 2023-06-19\n",
       "2126 2023-06-20\n",
       "2127 2023-06-21\n",
       "2128 2023-06-22\n",
       "2129 2023-06-23\n",
       "\n",
       "[2130 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date = pd.DataFrame(list(df_vh[\"Date\"].unique()))\n",
    "df_date.columns = [\"Date_join\"]\n",
    "df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d033e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_data_3 \n",
    "\n",
    "df = pd.read_excel('lay_gia.xlsx', sheet_name = \"Lay Gia\")\n",
    "df = df.iloc[2:]\n",
    "\n",
    "lst_column = list(df.iloc[0].values)\n",
    "lst_column = lst_column[1:]\n",
    "lst_column_new = []\n",
    "for i in lst_column:\n",
    "    index = i.index(' ')\n",
    "    k = i[:index]\n",
    "    lst_column_new.append(k)\n",
    "lst_column_new.insert(0, \"Date\")\n",
    "\n",
    "df.columns = lst_column_new\n",
    "df = df.iloc[4:]\n",
    "df = df.melt(id_vars=[\"Date\"], var_name=\"Stock\", value_name=\"Price\")\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"ETL_date\"] = str(dt.datetime.now())\n",
    "\n",
    "df = df.merge(df_date, how = \"left\", left_on=[\"Date\"], right_on=[\"Date_join\"])\n",
    "df = df[df[\"Date_join\"].isnull() == False]\n",
    "df = df[[\"Date\", \"Stock\", \"Price\", \"ETL_date\"]]\n",
    "df_gia = df.copy()\n",
    "\n",
    "#############################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_gia') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_gia\n",
    "\t(\n",
    "\t\t[Ngay] datetime2,\n",
    "        [Ma_ck] varchar(10),\n",
    "        [Price] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "#################################\n",
    "\n",
    "df.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gia.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_gia.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_gia')\n",
    "    cursor.executemany(''' INSERT INTO fact_gia Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "################################\n",
    "\n",
    "df_fl = pd.read_excel(\"Freefloat.xlsm\", sheet_name = \"Freefloat\")\n",
    "df_fl = df_fl.melt(id_vars=[\"Freefloat\"], var_name=\"Stock\", value_name=\"Freeloat1\")\n",
    "df_fl.columns = [\"Date\", \"Stock\", \"Freefloat\"]\n",
    "df_fl = df_fl.reset_index(drop=True)\n",
    "df_fl[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_fl.head(2) \n",
    "\n",
    "#################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_freefloat') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_freefloat\n",
    "\t(\n",
    "\t\t[Ngay] datetime2,\n",
    "        [Ma_ck] varchar(10),\n",
    "        [Freefloat_so_raw] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "##################################\n",
    "\n",
    "df_fl.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_freefloat.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_freefloat.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_freefloat')\n",
    "    cursor.executemany(''' INSERT INTO fact_freefloat Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e584359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_join</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>2023-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>2023-06-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>2023-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>2023-06-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date_join\n",
       "0    2014-12-10\n",
       "1    2014-12-11\n",
       "2    2014-12-12\n",
       "3    2014-12-15\n",
       "4    2014-12-16\n",
       "...         ...\n",
       "2125 2023-06-19\n",
       "2126 2023-06-20\n",
       "2127 2023-06-21\n",
       "2128 2023-06-22\n",
       "2129 2023-06-23\n",
       "\n",
       "[2130 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date = pd.DataFrame(list(df_vh[\"Date\"].unique()))\n",
    "df_date.columns = [\"Date_join\"]\n",
    "df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45ba3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gia = df_gia.merge(df_date, how = \"left\", left_on=[\"Date\"], right_on=[\"Date_join\"])\n",
    "df_gia = df_gia[df_gia[\"Date_join\"].isnull() == False]\n",
    "df_gia = df_gia[[\"Date\", \"Stock\", \"Price\", \"ETL_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e314c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_data_6\n",
    "\n",
    "lst_nam = [\"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "lst_thang = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n",
    "lst_path_text = []\n",
    "for i in lst_nam:\n",
    "    for j in lst_thang:\n",
    "        lst_path_text.append(f'D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\Market Update\\\\HSX\\\\Raw HSX\\\\Nuoc ngoai\\\\{i}\\\\Thang {j}')\n",
    "lst_path_text = [pathlib.Path(i) for i in lst_path_text]\n",
    "\n",
    "files = []\n",
    "for path in lst_path_text:\n",
    "    for direc in path.iterdir():\n",
    "        file = direc.stem\n",
    "        if not file.startswith(\"G\"):\n",
    "            files.append(direc)\n",
    "files\n",
    "\n",
    "####################\n",
    "\n",
    "lst_df = []\n",
    "for path in files:\n",
    "    date_name = path.stem\n",
    "    skiprows = [i for i in range(0,8)]\n",
    "    df = pd.read_excel(path, sheet_name=\"ExportData\", skiprows=lambda x: x in skiprows)\n",
    "    df = df.iloc[2:, :-1]\n",
    "    df[\"Ngay\"] = dt.datetime.strptime(date_name, \"%m.%d.%Y\")\n",
    "    lst_df.append(df)\n",
    "df_new = pd.DataFrame(pd.concat(lst_df))\n",
    "df_new = df_new[(df_new[\"Khối lượng mua(CP)\"].isnull() == False) & (df_new[\"Khối lượng Bán(CP)\"].isnull() == False)]\n",
    "df_new = df_new.reset_index(drop = True)\n",
    "df_new[\"ETL_Date\"] = str(dt.datetime.now())\n",
    "df_nuoc_ngoai = df_new.copy()\n",
    "    \n",
    "##########################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_nuoc_ngoai') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_nuoc_ngoai\n",
    "\t(\n",
    "        [Ma_ck] varchar(10),\n",
    "        [Khoi_luong_mua_cp] float,\n",
    "        [Gia_tri_mua_trieu_vnd] float,\n",
    "        [Khoi_luong_ban_cp] float,\n",
    "        [Gia_tri_ban_trieu_vnd] float,\n",
    "        [Khoi_luong_rong_cp] float,\n",
    "        [Gia_tri_rong_trieu_vnd] float,\n",
    "        [Khoi_luong_khop_lenh_mua_cp] float,\n",
    "        [Gia_tri_mua_khop_lenh_trieu_vnd] float,\n",
    "        [Khoi_luong_ban_khop_lenh_cp] float,\n",
    "        [Gia_tri_ban_khop_lenh_trieu_vnd] float,\n",
    "        [Khoi_luong_thoa_thuan_mua_cp] float,\n",
    "        [Gia_tri_mua_thoa_thuan_trieu_vnd] float,\n",
    "        [Khoi_luong_ban_thoa_thuan_cp] float,\n",
    "        [Gia_tri_ban_thoa_thuan_trieu_vnd] float,\n",
    "        [Room_nuoc_ngoai_con_lai_cp] float,\n",
    "        [Tong_room_nuoc_ngoai_duoc_phep_so_huu_cp] float,\n",
    "        [%_tong_room_nuoc_ngoai_duoc_phep_so_huu] float,\n",
    "        [Nuoc_ngoai_hien_dang_so_huu_cp] float,\n",
    "        [%_nuoc_ngoai_so_huu] float,\n",
    "        [Ngay] datetime2,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "#############################\n",
    "\n",
    "df_new.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_nuoc_ngoai.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_nuoc_ngoai.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_nuoc_ngoai')\n",
    "    cursor.executemany(''' INSERT INTO fact_nuoc_ngoai Values (?, ?, ?, ?, ?, ?,?, ?, ?, ?, ?, ?,?, ?, ?, ?, ?, ?,?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83a78197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_data_8\n",
    "\n",
    "lst_thang = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "lst_path_text = []\n",
    "for j in lst_thang:\n",
    "    lst_path_text.append(f'D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\Market Update\\\\HSX\\\\Raw HSX\\\\thong ke dat lenh\\\\thong ke dat lenh\\\\2022\\\\T{j}')\n",
    "lst_path_text = [pathlib.Path(i) for i in lst_path_text]\n",
    "\n",
    "files = []\n",
    "for path in lst_path_text:\n",
    "    for direc in path.iterdir():\n",
    "        file = direc.stem\n",
    "        if not file.startswith(\"G\"):\n",
    "            files.append(direc)\n",
    "files\n",
    "\n",
    "######################\n",
    "\n",
    "lst_df = []\n",
    "for path in files:\n",
    "    date_name = path.stem\n",
    "    skiprows = [i for i in range(0,11)]\n",
    "    df = pd.read_excel(path, sheet_name=\"ExportData\", skiprows=lambda x: x in skiprows)\n",
    "    df = df.iloc[2:, :-1]\n",
    "    df[\"Ngay\"] = dt.datetime.strptime(date_name, \"%m.%d.%Y\")\n",
    "    lst_df.append(df)\n",
    "\n",
    "df_new = pd.DataFrame(pd.concat(lst_df))\n",
    "df_new = df_new[(df_new[\"Dư mua(CP)\"].isnull() == False) & (df_new[\"Dư bán(CP)\"].isnull() == False)]\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_thong_ke_dat_lenh = df_new.copy()\n",
    "################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_thong_ke_dat_lenh') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_thong_ke_dat_lenh\n",
    "\t(\n",
    "        [Ma_ck] varchar(10),\n",
    "        [Du_mua_cp] float,\n",
    "        [Du_ban_cp] float,\n",
    "        [So_lenh_mua_lenh] float,\n",
    "        [Khoi_luong_mua_cp] float,\n",
    "        [Trung_binh_lenh_mua] float,\n",
    "        [So_lenh_ban] float,\n",
    "        [Khoi_luong_ban_cp] float,\n",
    "        [Trung_binh_lenh_ban] float,\n",
    "        [Chenh_lech_khoi_luong_dat_mua_dat_ban] float,\n",
    "        [Ngay] datetime2,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "#################################\n",
    "\n",
    "df_new.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_thong_ke_dat_lenh.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_thong_ke_dat_lenh.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_thong_ke_dat_lenh')\n",
    "    cursor.executemany(''' INSERT INTO fact_thong_ke_dat_lenh Values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26f3b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_data_9 \n",
    "df = pd.read_excel(\"VNItong.xlsm\")\n",
    "df = df.iloc[:, :-5]\n",
    "df = df[~(df[\"Ngày\"].dt.year == 2023)]\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df\n",
    "\n",
    "##########################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_vni') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_vni\n",
    "\t(\n",
    "        [Ngay] datetime2,\n",
    "        [Thay_doi] float,\n",
    "        [Mo_cua] float,\n",
    "        [Cao_nhat] float,\n",
    "        [Thap_nhat] float,\n",
    "        [Dong_cua] float,\n",
    "        [Khop_lenh_khoi_luong_cp] float,\n",
    "        [Gia_tri_khop_lenh_ty_vnd] float,\n",
    "        [Thoa_thuan_khoi_luong_cp] float,\n",
    "        [Gia_tri_thoa_thuan_ty_vnd] float,\n",
    "        [KLGD_cp] float,\n",
    "        [GTGD_ty_vnd] float,\n",
    "        [Von_hoa_ty_vnd] float,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "###########################\n",
    "\n",
    "df.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_vni.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_vni.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_vni')\n",
    "    cursor.executemany(''' INSERT INTO fact_vni Values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8680132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3474162970.py:38: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new.fillna(value=0)\n"
     ]
    }
   ],
   "source": [
    "# ETL_data_10\n",
    "\n",
    "lst_nam = [\"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "lst_thang = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n",
    "lst_path_text = []\n",
    "for i in lst_nam:\n",
    "    for j in lst_thang:\n",
    "        lst_path_text.append(f'D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\Market Update\\\\HSX\\\\Raw HSX\\\\VNI chi tiet\\\\{i}\\\\Thang {j}')\n",
    "lst_path_text = [pathlib.Path(i) for i in lst_path_text]\n",
    "\n",
    "files = []\n",
    "for path in lst_path_text:\n",
    "    for direc in path.iterdir():\n",
    "        file = direc.stem\n",
    "        if not file.startswith(\"G\"):\n",
    "            files.append(direc)\n",
    "files\n",
    "\n",
    "########################################\n",
    "\n",
    "lst_df = []\n",
    "for path in files:\n",
    "    date_name = path.stem\n",
    "    skiprows = [i for i in range(0,8)]\n",
    "    df = pd.read_excel(path, sheet_name=\"ExportData\", skiprows=lambda x: x in skiprows)\n",
    "    df = df.iloc[:, :-1]\n",
    "    lst_columns = [\"Ma_ck\", \"Thay_doi(+/-%)\", \"Mo_cua\", \"Cao_nhat\", \"Thap_nhat\", \"Dong_cua\", \"Khop_lenh_khoi_luong\", \"Khop_lenh_gia_tri\",\n",
    "                \"Thoa_thuan_khoi_luong\", \"Thoa_thuan_gia_tri\", \"KLGD(CP)\", \"GTGD(trieu_VND)\", \"Von_hoa(trieu_VND)\"]\n",
    "    df.columns = lst_columns\n",
    "    df[\"Ngay\"] = dt.datetime.strptime(date_name, \"%m.%d.%Y\")\n",
    "    df = df.iloc[3:]\n",
    "    lst_df.append(df)\n",
    "\n",
    "df_new = pd.DataFrame(pd.concat(lst_df))\n",
    "df_new[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_new = df_new[(df_new[\"Mo_cua\"].isnull() == False) & (df_new[\"Cao_nhat\"].isnull() == False)]\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new.fillna(value=0)\n",
    "df_new[\"Khop_lenh_khoi_luong\"] = df_new[\"Khop_lenh_khoi_luong\"].astype(float)\n",
    "df_new[\"Khop_lenh_gia_tri\"] = df_new[\"Khop_lenh_gia_tri\"].astype(float)\n",
    "df_new[\"Thoa_thuan_khoi_luong\"] = df_new[\"Thoa_thuan_khoi_luong\"].astype(float)\n",
    "df_new[\"Thoa_thuan_gia_tri\"] = df_new[\"Thoa_thuan_gia_tri\"].astype(float)\n",
    "df_vni_chi_tiet = df_new.copy()\n",
    "\n",
    "##########################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_vni_chi_tiet') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_vni_chi_tiet\n",
    "\t(\n",
    "        [Ma_ck] varchar(10),\n",
    "        [Thay_doi(+/-%)] float,\n",
    "        [Mo_cua] float,\n",
    "        [Cao_nhat] float,\n",
    "        [Thap_nhat] float,\n",
    "        [Dong_cua] float,\n",
    "        [Khop_lenh_khoi_luong_cp] float,\n",
    "        [Khop_lenh_gia_tri_trieu_vnd] float,\n",
    "        [Thoa_thuan_khoi_luong_cp] float,\n",
    "        [Thoa_thuan_gia_tri_trieu_vnd] float,\n",
    "        [KLGD(CP)] float,\n",
    "        [GTGD(trieu_VND)] float,\n",
    "        [Von_hoa(trieu_VND)] float,\n",
    "        [Ngay] datetime2,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "###########################################\n",
    "\n",
    "df_new.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_vni_chi_tiet.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_vni_chi_tiet.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_vni_chi_tiet')\n",
    "    cursor.executemany(''' INSERT INTO fact_vni_chi_tiet Values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ea9820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_data_11\n",
    "\n",
    "path_text = r'D:\\Tin hoc\\Project\\Thong ke thi truong\\Market Update\\HSX\\Raw HSX\\Chi_tiet_lich_su_gia_Index'\n",
    "path = pathlib.Path(path_text)\n",
    "lst = os.listdir(path)\n",
    "\n",
    "lst_path_new = []\n",
    "for i in lst:\n",
    "    path_new = path/i \n",
    "    lst_path_new.append(path_new)\n",
    "\n",
    "file = []\n",
    "for direc in lst_path_new:\n",
    "    for i in direc.iterdir():\n",
    "        k = i.suffix\n",
    "        if k == '.csv':\n",
    "            file.append(i)\n",
    "\n",
    "##############################\n",
    "\n",
    "lst_df = []\n",
    "for path in file:\n",
    "    type_name = path.stem \n",
    "    df = pd.read_csv(path)\n",
    "    df[\"type\"] = type_name \n",
    "    lst_df.append(df)\n",
    "\n",
    "df_new = pd.DataFrame(pd.concat(lst_df))\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_new[\"Vol.\"] = df_new[\"Vol.\"].fillna(0)\n",
    "df_new[\"Vol_new\"] = df_new[\"Vol.\"].str.slice(0,-1)\n",
    "df_new[\"Vol_new\"] = df_new[\"Vol_new\"].astype(str)\n",
    "df_new['Vol_new'] = df_new['Vol_new'].replace(np.nan, '0')\n",
    "df_new['abc'] = df_new[\"Vol.\"].str.slice(-1)\n",
    "df_new['abc'] = df_new['abc'].fillna('-')\n",
    "\n",
    "lst = list(df_new[\"Vol_new\"].values)\n",
    "lst_new = []\n",
    "for i in lst:\n",
    "    g = i.find(',')\n",
    "    if g == -1:\n",
    "        lst_new.append(i)\n",
    "    else:\n",
    "        k = i.replace(',','_')\n",
    "        lst_new.append(k)\n",
    "lst_new = [0 if i == '' else i for i in lst_new]\n",
    "lst_new = [float(i) for i in lst_new]\n",
    "df_lst_new = pd.DataFrame(lst_new)\n",
    "df_new['Vol_new'] = df_lst_new\n",
    "df_new['Vol_new'] = df_new['Vol_new'].fillna(0)\n",
    "\n",
    "def phan_loai_1(row):\n",
    "    last_word = row.loc[\"abc\"]\n",
    "    vol_new = row.loc[\"Vol_new\"]\n",
    "\n",
    "    if last_word == 'B':\n",
    "        return vol_new * 1000000000\n",
    "        \n",
    "    elif last_word == 'K':\n",
    "        return vol_new * 1000\n",
    "        \n",
    "    elif last_word == 'M':\n",
    "        return vol_new * 1000000\n",
    "\n",
    "    else: return vol_new\n",
    "\n",
    "df_new['Vol_new'] = df_new.apply(phan_loai_1, axis=\"columns\")\n",
    "df_new = df_new[[\"Date\", \"Price\", \"Open\", \"High\", \"Low\", \"Vol_new\", \"type\", \"ETL_date\"]]\n",
    "df_new[\"Date\"] = df_new[\"Date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "lst_ten = [\"Price\", \"Open\", \"High\", \"Low\"]\n",
    "for t in lst_ten:\n",
    "    df_new[t] = df_new[t].astype(str)\n",
    "    lst = list(df_new[t].values)\n",
    "    lst_new = []\n",
    "    for i in lst:\n",
    "        g = i.find(',')\n",
    "        if g == -1:\n",
    "            lst_new.append(i)\n",
    "        else:\n",
    "            k = i.replace(',','_')\n",
    "            lst_new.append(k)\n",
    "    lst_new = [0 if i == '' else i for i in lst_new]\n",
    "    lst_new = [float(i) for i in lst_new]\n",
    "    df_lst_new = pd.DataFrame(lst_new)\n",
    "    df_new[t] = df_lst_new\n",
    "    df_new[t] = df_new[t].fillna(0)\n",
    "    df_new[t] = df_new[t].astype(float)\n",
    "df_new\n",
    "\n",
    "##################################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_index') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_index\n",
    "\t(\n",
    "\t\t[Date] datetime2,\n",
    "\t\t[Price] float,\n",
    "        [Open] float,\n",
    "        [High] float,\n",
    "        [Low] float,\n",
    "        [Vol_new] float,\n",
    "        [type] varchar(50),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "##############################\n",
    "\n",
    "df_new.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_index.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_index.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_index')\n",
    "    cursor.executemany(''' INSERT INTO fact_index Values (?, ?, ?, ?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9725c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:113: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].fillna(0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:113: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].fillna(0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:113: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].fillna(0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:114: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].replace('-', 0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:113: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].fillna(0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:113: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].fillna(0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:114: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].replace('-', 0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:113: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].fillna(0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:113: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].fillna(0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:114: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].replace('-', 0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:113: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].fillna(0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6880\\3412205637.py:113: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new[i] = df_new[i].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# ETL_data_12\n",
    "\n",
    "lst_date_gia = list(df_gia[\"Date\"].unique())\n",
    "df_date_gia = pd.DataFrame(lst_date_gia)\n",
    "df_date_gia.columns = [\"date_gia\"]\n",
    "df_date_gia\n",
    "\n",
    "lst = pd.date_range(start=\"2014-12-11\", end=\"2022-12-31\", freq=\"D\")\n",
    "df = pd.DataFrame(lst)\n",
    "df.columns = [\"date\"]\n",
    "df[\"week_day\"] = df[\"date\"].dt.weekday\n",
    "df = df.merge(df_date_gia, how='left', left_on='date', right_on='date_gia')\n",
    "df[\"date_gia\"] = df[\"date_gia\"].astype(str)\n",
    "# df[\"date_id\"] = df.apply(lambda row: if row[\"week_day\"], axis=1)\n",
    "\n",
    "lst_day = [int(i) for i in list(df[\"week_day\"].values)]\n",
    "lst_date_gia = list(df[\"date_gia\"].values)\n",
    "count = 0\n",
    "lst_date_id = []\n",
    "for j,i in enumerate(lst_day): \n",
    "    if i in (0,1,2,3,4) and lst_date_gia[j] != 'NaT':\n",
    "        count = count + 1\n",
    "        lst_date_id.append(count)\n",
    "    else:\n",
    "        lst_date_id.append(0)\n",
    "\n",
    "df[\"date_id\"] = pd.DataFrame(lst_date_id)\n",
    "df[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df = df[[\"date\", \"week_day\", \"date_id\", \"ETL_date\"]]\n",
    "\n",
    "#################################\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_date_id') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_date_id\n",
    "\t(\n",
    "\t\t[date] datetime2,\n",
    "\t\t[week_day] int,\n",
    "        [date_id] int,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "#####################################\n",
    "\n",
    "df.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_date_id.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_date_id.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_date_id')\n",
    "    cursor.executemany(''' INSERT INTO dim_date_id Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "#####################################\n",
    "\n",
    "path_text = r'D:\\Tin hoc\\Project\\Thong ke thi truong\\Market Update\\HSX\\Du no margin'\n",
    "path = pathlib.Path(path_text)\n",
    "lst = os.listdir(path)\n",
    "\n",
    "lst_path_new = []\n",
    "for i in lst:\n",
    "    path_new = path/i \n",
    "    lst_path_new.append(path_new)\n",
    "\n",
    "lst_path_new\n",
    "\n",
    "####################################\n",
    "\n",
    "lst_df = []\n",
    "for path in lst_path_new:\n",
    "    date_name = path.stem\n",
    "    skiprows = [i for i in range(0,11)]\n",
    "    df = pd.read_excel(path, sheet_name=\"ExportData\", skiprows=lambda x: x in skiprows)\n",
    "\n",
    "    df1 = pd.DataFrame(df.iloc[0])\n",
    "    df1.columns = ['cot']\n",
    "    df1 = df1.reset_index()\n",
    "\n",
    "    lst = list(df1['index'].values)\n",
    "    for i,j in enumerate(lst):\n",
    "        if j.startswith('U'):\n",
    "            k = lst[i-1]\n",
    "            lst[i] = k \n",
    "    df1['index'] =  pd.DataFrame(lst)\n",
    "    df1 = df1.iloc[1:]\n",
    "    df1['column'] = df1['index'].str.slice(0,2,1) + ' - ' + df1['cot'] \n",
    "    lst_column = list(df1['column'].values)\n",
    "    lst_column.insert(0, 'Cong ty chung khoan')\n",
    "\n",
    "    df.columns = lst_column\n",
    "    df = df.iloc[2:]\n",
    "    df[\"Nam\"] = date_name\n",
    "    df[\"Nam\"] = df[\"Nam\"].astype(int)\n",
    "\n",
    "    lst_df.append(df)\n",
    "\n",
    "df_new = pd.DataFrame(pd.concat(lst_df))\n",
    "df_new[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_new = df_new.reset_index(drop = True)\n",
    "df_new = df_new[(df_new[\"Q1 - Nợ vay ký quỹ (Tỷ VND)\"].isnull() == False) & (df_new[\"Q1 - Nợ vay ký quỹ/ Vốn chủ sở hữu (%)\"].isnull() == False)]\n",
    "df_new[\"Cong ty chung khoan\"] = df_new[\"Cong ty chung khoan\"].fillna('null')\n",
    "\n",
    "lst_column1 = list(df_new.columns)\n",
    "lst_column1 = lst_column1[1:-2]\n",
    "\n",
    "for i in lst_column1:\n",
    "    df_new[i] = df_new[i].fillna(0)\n",
    "    df_new[i] = df_new[i].replace('-', 0)\n",
    "    df_new[i] = df_new[i].astype(float)\n",
    "\n",
    "df_new\n",
    "\n",
    "##############################\n",
    "\n",
    "query = '''if (OBJECT_ID('fact_margin') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table fact_margin\n",
    "\t(\n",
    "\t\t[Cong ty chung khoan] nvarchar(100),\n",
    "\t\t[Q1_No_vay_ky_quy(Ty_VND)] float,\n",
    "        [Q1_No_vay_ky_quy_/_Von_chu_so_huu_(%)] float,\n",
    "        [Q1_No_vay_ky_quy_/_Tong_tai_san_(%)] float,\n",
    "        [Q2_No_vay_ky_quy_(Ty_VND)] float,\n",
    "        [Q2_No_vay_ky_quy_/_von_chu_so_huu_(%)] float,\n",
    "        [Q2_No_vay_ky_quy_/_Tong_tai_san_(%)] float,\n",
    "        [Q3_No_vay_ky_quy_(Ty_VND)] float,\n",
    "        [Q3_No_vay_ky_quy_/_von_chu_so_huu_(%)] float,\n",
    "        [Q3_No_vay_ky_quy_/_Tong_tai_san_(%)] float,\n",
    "        [Q4_No_vay_ky_quy_(Ty_VND)] float,\n",
    "        [Q4_No_vay_ky_quy_/_von_chu_so_huu_(%)] float,\n",
    "        [Q4_No_vay_ky_quy_/_Tong_tai_san_(%)] float,\n",
    "        [Nam] int,\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "#################################\n",
    "\n",
    "df_new.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_margin.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\fact_margin.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE fact_margin')\n",
    "    cursor.executemany(''' INSERT INTO fact_margin Values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15a344da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_investor_group = pd.DataFrame(list(set(lst_phan_nhom)), columns=[\"investor\"])\n",
    "df_investor_group.loc[-1] = [df_tu_doanh[\"phan_loai\"].unique()[0]]\n",
    "df_investor_group[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_investor_group = df_investor_group.reset_index(drop=True)\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_investor') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_investor\n",
    "\t(\n",
    "\t\t[investor] nvarchar(100),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_investor_group.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_investor.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_investor.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_investor')\n",
    "    cursor.executemany(''' INSERT INTO dim_investor Values (?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_data_7 \n",
    "\n",
    "skiprows = [i for i in range(0,7)]\n",
    "df = pd.read_excel(\"Look_up_nganh.xlsm\", sheet_name=\"ExportData\", skiprows=lambda x: x in skiprows)\n",
    "df = df.iloc[1:453, 1:]\n",
    "df = df.reset_index(drop=True)\n",
    "df.columns = [\"Ma_ck\", \"Ten\", \"San\", \"Lv1\", \"Lv2\", \"Lv3\", \"Lv4\", \"Lv5\"]\n",
    "df \n",
    "\n",
    "#################\n",
    "\n",
    "df_phan_nganh = df[[\"Ma_ck\", \"Lv1\", \"Lv2\", \"Lv3\", \"Lv4\", \"Lv5\"]].copy()\n",
    "lst_index = list(df_phan_nganh.index)\n",
    "df_phan_nganh[\"id_stock\"] = pd.DataFrame(lst_index)\n",
    "df_phan_nganh\n",
    "\n",
    "#################\n",
    "\n",
    "lst_lv1 = df[\"Lv1\"].unique()\n",
    "df_lv1 = pd.DataFrame(lst_lv1)\n",
    "df_lv1.columns = [\"phan_nganh_lv1\"]\n",
    "lst_index_lv1 = list(df_lv1.index)\n",
    "df_lv1[\"id_lv1\"] = pd.DataFrame(lst_index_lv1)\n",
    "df_lv1[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv1\n",
    "\n",
    "###################\n",
    "\n",
    "lst_lv2 = df[\"Lv2\"].unique()\n",
    "df_lv2 = pd.DataFrame(lst_lv2)\n",
    "df_lv2.columns = [\"phan_nganh_lv2\"]\n",
    "lst_index_lv2 = list(df_lv2.index)\n",
    "df_lv2[\"id_lv2\"] = pd.DataFrame(lst_index_lv2)\n",
    "# df_lv2.loc[-1] = [\"Chưa phân ngành\", -1]\n",
    "df_lv2[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv2\n",
    "\n",
    "##################################\n",
    "\n",
    "lst_lv3 = df[\"Lv3\"].unique()\n",
    "df_lv3 = pd.DataFrame(lst_lv3)\n",
    "df_lv3.columns = [\"phan_nganh_lv3\"]\n",
    "lst_index_lv3 = list(df_lv3.index)\n",
    "df_lv3[\"id_lv3\"] = pd.DataFrame(lst_index_lv3)\n",
    "# df_lv3.loc[-1] = [\"Chưa phân ngành\", -1]\n",
    "df_lv3[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv3\n",
    "\n",
    "##################################\n",
    "\n",
    "lst_lv4 = df[\"Lv4\"].unique()\n",
    "df_lv4 = pd.DataFrame(lst_lv4)\n",
    "df_lv4.columns = [\"phan_nganh_lv4\"]\n",
    "lst_index_lv4 = list(df_lv4.index)\n",
    "df_lv4[\"id_lv4\"] = pd.DataFrame(lst_index_lv4)\n",
    "# df_lv4.loc[-1] = [\"Chưa phân ngành\", -1]\n",
    "df_lv4[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv4\n",
    "\n",
    "####################################\n",
    "\n",
    "lst_lv5 = df[\"Lv5\"].unique()\n",
    "df_lv5 = pd.DataFrame(lst_lv5)\n",
    "df_lv5.columns = [\"phan_nganh_lv5\"]\n",
    "lst_index_lv5 = list(df_lv5.index)\n",
    "df_lv5[\"id_lv5\"] = pd.DataFrame(lst_index_lv5)\n",
    "# df_lv5.loc[-1] = [\"Chưa phân ngành\", -1]\n",
    "df_lv5[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv5\n",
    "\n",
    "###########################################\n",
    "\n",
    "df_phan_nganh = df_phan_nganh.merge(right=df_lv1, how='left', left_on='Lv1', right_on=\"phan_nganh_lv1\").drop(columns=[\"phan_nganh_lv1\", \"Lv1\", \"ETL_date\"], axis=1)\n",
    "df_phan_nganh = df_phan_nganh.merge(right=df_lv2, how='left', left_on='Lv2', right_on=\"phan_nganh_lv2\").drop(columns=[\"phan_nganh_lv2\", \"Lv2\", \"ETL_date\"], axis=1)\n",
    "df_phan_nganh = df_phan_nganh.merge(right=df_lv3, how='left', left_on='Lv3', right_on=\"phan_nganh_lv3\").drop(columns=[\"phan_nganh_lv3\", \"Lv3\", \"ETL_date\"], axis=1)\n",
    "df_phan_nganh = df_phan_nganh.merge(right=df_lv4, how='left', left_on='Lv4', right_on=\"phan_nganh_lv4\").drop(columns=[\"phan_nganh_lv4\", \"Lv4\", \"ETL_date\"], axis=1)\n",
    "df_phan_nganh = df_phan_nganh.merge(right=df_lv5, how='left', left_on='Lv5', right_on=\"phan_nganh_lv5\").drop(columns=[\"phan_nganh_lv5\", \"Lv5\", \"ETL_date\"], axis=1)\n",
    "df_phan_nganh = df_phan_nganh.fillna(-1)\n",
    "df_phan_nganh[\"id_stock\"] = df_phan_nganh[\"id_stock\"].astype(int)\n",
    "df_phan_nganh[\"id_lv1\"] = df_phan_nganh[\"id_lv1\"].astype(str) + '.1'\n",
    "df_phan_nganh[\"id_lv2\"] = df_phan_nganh[\"id_lv2\"].astype(str) + '.2'\n",
    "df_phan_nganh[\"id_lv3\"] = df_phan_nganh[\"id_lv3\"].astype(str) + '.3'\n",
    "df_phan_nganh[\"id_lv4\"] = df_phan_nganh[\"id_lv4\"].astype(str) + '.4'\n",
    "df_phan_nganh[\"id_lv5\"] = df_phan_nganh[\"id_lv5\"].astype(str) + '.5'\n",
    "df_phan_nganh.columns = [\"Ma_ck\", \"id_stock\", \"Cấp 1\", \"Cấp 2\", \"Cấp 3\", \"Cấp 4\", \"Cấp 5\"]\n",
    "df_phan_nganh = df_phan_nganh.melt(id_vars=[\"Ma_ck\", \"id_stock\"], var_name=\"Phan_loai\", value_name=\"id_phan_nganh\")\n",
    "df_phan_nganh[\"ETL_date\"] = str(dt.datetime.now())\n",
    "\n",
    "#################################\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_phan_nganh') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_phan_nganh\n",
    "\t(\n",
    "        [Ma_ck] varchar(10),\n",
    "        [id_stock] int,\n",
    "        [phan_loai] nvarchar(20), \n",
    "        [id_phan_nganh] varchar(10),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "#########################\n",
    "\n",
    "df_phan_nganh.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_phan_nganh.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_phan_nganh.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_phan_nganh')\n",
    "    cursor.executemany(''' INSERT INTO dim_phan_nganh Values (?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "###########################################\n",
    "\n",
    "lst_lv1 = df[\"Lv1\"].unique()\n",
    "df_lv1 = pd.DataFrame(lst_lv1)\n",
    "df_lv1.columns = [\"ten_nganh\"]\n",
    "lst_index_lv1 = list(df_lv1.index)\n",
    "df_lv1[\"id\"] = pd.DataFrame(lst_index_lv1)\n",
    "df_lv1[\"id\"] = df_lv1[\"id\"].astype(str)\n",
    "df_lv1[\"id\"] = df_lv1[\"id\"] + '.1'\n",
    "df_lv1[\"phan_nganh\"] = \"Cấp 1\"\n",
    "df_lv1[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv1.head(2)\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_nganh_lv1') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_nganh_lv1\n",
    "\t(\n",
    "        [ten_nganh] nvarchar(100),\n",
    "        [id] varchar(10),\n",
    "        [phan_nganh] nvarchar(20),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_lv1.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv1.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv1.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_nganh_lv1')\n",
    "    cursor.executemany(''' INSERT INTO dim_nganh_lv1 Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "##################################################\n",
    "\n",
    "lst_lv2 = df[\"Lv2\"].unique()\n",
    "df_lv2 = pd.DataFrame(lst_lv2)\n",
    "df_lv2.columns = [\"ten_nganh\"]\n",
    "lst_index_lv2 = list(df_lv2.index)\n",
    "df_lv2[\"id\"] = pd.DataFrame(lst_index_lv2)\n",
    "df_lv2[\"id\"] = df_lv2[\"id\"].astype(str)\n",
    "df_lv2[\"id\"] = df_lv2[\"id\"] + '.2'\n",
    "df_lv2[\"phan_nganh\"] = \"Cấp 2\"\n",
    "df_lv2[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv2.head(2)\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_nganh_lv2') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_nganh_lv2\n",
    "\t(\n",
    "        [ten_nganh] nvarchar(100),\n",
    "        [id] varchar(10),\n",
    "        [phan_nganh] nvarchar(20),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_lv2.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv2.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv2.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_nganh_lv2')\n",
    "    cursor.executemany(''' INSERT INTO dim_nganh_lv2 Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "##############################################\n",
    "\n",
    "lst_lv3 = df[\"Lv3\"].unique()\n",
    "df_lv3 = pd.DataFrame(lst_lv3)\n",
    "df_lv3.columns = [\"ten_nganh\"]\n",
    "lst_index_lv3 = list(df_lv3.index)\n",
    "df_lv3[\"id\"] = pd.DataFrame(lst_index_lv3)\n",
    "df_lv3[\"id\"] = df_lv3[\"id\"].astype(str)\n",
    "df_lv3[\"id\"] = df_lv3[\"id\"] + '.3'\n",
    "df_lv3[\"phan_nganh\"] = \"Cấp 3\"\n",
    "df_lv3[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv3.head(2)\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_nganh_lv3') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_nganh_lv3\n",
    "\t(\n",
    "        [ten_nganh] nvarchar(100),\n",
    "        [id] varchar(10),\n",
    "        [phan_nganh] nvarchar(20),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_lv3.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv3.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv3.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_nganh_lv3')\n",
    "    cursor.executemany(''' INSERT INTO dim_nganh_lv3 Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "######################################################\n",
    "\n",
    "lst_lv4 = df[\"Lv4\"].unique()\n",
    "df_lv4 = pd.DataFrame(lst_lv4)\n",
    "df_lv4.columns = [\"ten_nganh\"]\n",
    "lst_index_lv4 = list(df_lv4.index)\n",
    "df_lv4[\"id\"] = pd.DataFrame(lst_index_lv4)\n",
    "df_lv4[\"id\"] = df_lv4[\"id\"].astype(str)\n",
    "df_lv4[\"id\"] = df_lv4[\"id\"] + '.4'\n",
    "df_lv4[\"phan_nganh\"] = \"Cấp 4\"\n",
    "df_lv4[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv4.head(2)\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_nganh_lv4') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_nganh_lv4\n",
    "\t(\n",
    "        [ten_nganh] nvarchar(100),\n",
    "        [id] varchar(10),\n",
    "        [phan_nganh] nvarchar(20),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_lv4.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv4.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv4.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_nganh_lv4')\n",
    "    cursor.executemany(''' INSERT INTO dim_nganh_lv4 Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "##########################################################\n",
    "\n",
    "lst_lv5 = df[\"Lv5\"].unique()\n",
    "df_lv5 = pd.DataFrame(lst_lv5)\n",
    "df_lv5.columns = [\"ten_nganh\"]\n",
    "lst_index_lv5 = list(df_lv5.index)\n",
    "df_lv5[\"id\"] = pd.DataFrame(lst_index_lv5)\n",
    "df_lv5[\"id\"] = df_lv5[\"id\"].astype(str)\n",
    "df_lv5[\"id\"] = df_lv5[\"id\"] + '.5'\n",
    "df_lv5[\"phan_nganh\"] = \"Cấp 5\"\n",
    "df_lv5[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_lv5.head(2)\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_nganh_lv5') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_nganh_lv5\n",
    "\t(\n",
    "        [ten_nganh] nvarchar(100),\n",
    "        [id] varchar(10),\n",
    "        [phan_nganh] nvarchar(20),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_lv5.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv5.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_lv5.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_nganh_lv5')\n",
    "    cursor.executemany(''' INSERT INTO dim_nganh_lv5 Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "df_phan_nganh_cac_cap = pd.concat([df_lv1, df_lv2, df_lv3, df_lv4, df_lv5])\n",
    "df_phan_nganh_cac_cap = df_phan_nganh_cac_cap.reset_index(drop=True)\n",
    "df_phan_nganh_cac_cap[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_phan_nganh_cac_cap\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_nganh_cac_cap') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_nganh_cac_cap\n",
    "\t(\n",
    "        [ten_nganh] nvarchar(100),\n",
    "        [id] varchar(10),\n",
    "        [phan_nganh] nvarchar(20),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_phan_nganh_cac_cap.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_cac_cap.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_nganh_cac_cap.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_nganh_cac_cap')\n",
    "    cursor.executemany(''' INSERT INTO dim_nganh_cac_cap Values (?, ?, ?, ?)''', reader)\n",
    "    conn.commit()\n",
    "    \n",
    "##########################################\n",
    "\n",
    "lst_phan_cap = [\"Cấp 1\", \"Cấp 2\", \"Cấp 3\", \"Cấp 4\", \"Cấp 5\"]\n",
    "df_phan_cap = pd.DataFrame(lst_phan_cap)\n",
    "df_phan_cap.columns = [\"cap_nganh\"]\n",
    "df_phan_cap[\"ETL_date\"] = str(dt.datetime.now())\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_cap_nganh') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_cap_nganh\n",
    "\t(\n",
    "        [cap_nganh] nvarchar(20),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_phan_cap.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_cap_nganh.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_cap_nganh.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_cap_nganh')\n",
    "    cursor.executemany(''' INSERT INTO dim_cap_nganh Values (?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "065596bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ck_gtm = list(df_gtm[\"Ma_ck\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "581ece28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ck_klm = list(df_klm[\"Ma_ck\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfb64171",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ck_gtb = list(df_gtb[\"Ma_ck\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db9c3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ck_klb = list(df_klb[\"Ma_ck\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c38eee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ck_gtr = list(df_gtr[\"Ma_ck\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4e3e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ck_klr = list(df_klr[\"Ma_ck\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08b151dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tu_doanh\n",
    "lst_ck_tu_doanh = list(df_tu_doanh[\"Mã CK\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "108abd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_thoa_thuan\n",
    "lst_ck_thoa_thuan = list(df_thoa_thuan[\"Ma_CK\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50622e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gtgdkl\n",
    "lst_ck_gtgdkl = list(df_gtgdkl[\"Ma_CK\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94792017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_klgdkl\n",
    "lst_ck_klgdkl = list(df_klgdkl[\"Ma_CK\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "225b7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_slcplh\n",
    "lst_ck_slcplh = list(df_slcplh[\"Ma_CK\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6b31c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vh\n",
    "lst_ck_vh = list(df_vh[\"Ma_CK\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80de0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gia\n",
    "lst_ck_gia = list(df_gia[\"Stock\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d3809b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fl\n",
    "lst_ck_fl = list(df_fl[\"Stock\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e4bc589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nuoc_ngoai\n",
    "lst_ck_nuoc_ngoai = list(df_nuoc_ngoai[\"Mã CK\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcde4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_phan_nganh\n",
    "lst_ck_phan_nganh = list(df_phan_nganh[\"Ma_ck\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3863803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_thong_ke_dat_lenh\n",
    "lst_ck_thong_ke_dat_lenh = list(df_thong_ke_dat_lenh[\"Mã CK\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a585377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vni_chi_tiet\n",
    "lst_ck_vni_chi_tiet = list(df_vni_chi_tiet[\"Ma_ck\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9b7ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ck_unique = lst_ck_gtm + lst_ck_klm + lst_ck_gtb + lst_ck_klb + lst_ck_gtr + lst_ck_klr + lst_ck_tu_doanh \\\n",
    "                + lst_ck_thoa_thuan + lst_ck_gtgdkl + lst_ck_klgdkl + lst_ck_slcplh + lst_ck_vh + lst_ck_gia  \\\n",
    "                + lst_ck_fl + lst_ck_nuoc_ngoai + lst_ck_phan_nganh + lst_ck_thong_ke_dat_lenh + lst_ck_vni_chi_tiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89c95390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ma_Ck_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DGC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>CMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>EIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>TDW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>HSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>FUEKIV30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ma_Ck_unique\n",
       "0            KMR\n",
       "1            THI\n",
       "2            DGC\n",
       "3            SCD\n",
       "4            PTC\n",
       "..           ...\n",
       "447          CMX\n",
       "448          EIB\n",
       "449          TDW\n",
       "450          HSL\n",
       "451     FUEKIV30\n",
       "\n",
       "[452 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_ck_unique = list(set(lst_ck_unique))\n",
    "df_ck_unique = pd.DataFrame(lst_ck_unique)\n",
    "df_ck_unique.columns = [\"Ma_Ck_unique\"]\n",
    "df_ck_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "885c4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phan_nganh_pivot = df_phan_nganh.pivot(columns=[\"Phan_loai\"], values=[\"id_phan_nganh\"], index=[\"Ma_ck\", \"id_stock\"])\n",
    "df_phan_nganh_pivot.columns = [\"id_lv1\", \"id_lv2\", \"id_lv3\", \"id_lv4\", \"id_lv5\"]\n",
    "df_phan_nganh_pivot = df_phan_nganh_pivot.reset_index(drop=False)\n",
    "\n",
    "df_stock = pd.read_csv(r'D:\\Tin hoc\\Project\\Thong ke thi truong\\Market Update\\HSX\\Stock\\stock.csv')\n",
    "df_stock = df_stock.merge(right = df_phan_nganh_pivot, how = 'left', left_on='Ma_ck', right_on=\"Ma_ck\")\n",
    "df_stock = df_stock[[\"Stock Id\", \"Ma_ck\", \"Ten_doanh_nghiep\", \"id_lv1\", \"id_lv2\", \"id_lv3\", \"id_lv4\", \"id_lv5\"]]\n",
    "df_stock = df_stock.fillna(-1)\n",
    "df_stock = df_stock.merge(df_ck_unique, how = 'right', left_on='Ma_ck', right_on='Ma_Ck_unique')\n",
    "df_stock[\"Stock Id\"] = df_stock[\"Stock Id\"].fillna(-1)\n",
    "df_stock[\"Stock Id\"] = df_stock[\"Stock Id\"].astype(int)\n",
    "df_stock[\"id_lv1\"] = df_stock[\"id_lv1\"].fillna(-1)\n",
    "df_stock[\"id_lv2\"] = df_stock[\"id_lv2\"].fillna(-1)\n",
    "df_stock[\"id_lv3\"] = df_stock[\"id_lv3\"].fillna(-1)\n",
    "df_stock[\"id_lv4\"] = df_stock[\"id_lv4\"].fillna(-1)\n",
    "df_stock[\"id_lv5\"] = df_stock[\"id_lv5\"].fillna(-1)\n",
    "df_stock[\"Ten_doanh_nghiep\"] = df_stock[\"Ten_doanh_nghiep\"].fillna('Blank')\n",
    "df_stock = df_stock[[\"Stock Id\", \"Ma_Ck_unique\", \"Ten_doanh_nghiep\", \"id_lv1\", \"id_lv2\", \"id_lv3\", \"id_lv4\", \"id_lv5\"]]\n",
    "df_stock.columns = [\"Stock Id\", \"Ma_ck\", \"Ten_doanh_nghiep\", \"id_lv1\", \"id_lv2\", \"id_lv3\", \"id_lv4\", \"id_lv5\"]\n",
    "\n",
    "df_stock[\"ETL_date\"] = str(dt.datetime.now())\n",
    "df_stock = df_stock.merge(df_phan_nganh_cac_cap, how = 'left', left_on='id_lv1', right_on='id').drop(columns=['ETL_date_x', 'id', 'phan_nganh', 'ETL_date_y']).rename(columns={'ten_nganh': 'ten_nganh_lv1'})\n",
    "df_stock = df_stock.merge(df_phan_nganh_cac_cap, how = 'left', left_on='id_lv2', right_on='id').drop(columns=['ETL_date', 'id', 'phan_nganh']).rename(columns={'ten_nganh': 'ten_nganh_lv2'})\n",
    "df_stock = df_stock.merge(df_phan_nganh_cac_cap, how = 'left', left_on='id_lv3', right_on='id').drop(columns=['ETL_date', 'id', 'phan_nganh']).rename(columns={'ten_nganh': 'ten_nganh_lv3'})\n",
    "df_stock = df_stock.merge(df_phan_nganh_cac_cap, how = 'left', left_on='id_lv4', right_on='id').drop(columns=['ETL_date', 'id', 'phan_nganh']).rename(columns={'ten_nganh': 'ten_nganh_lv4'})\n",
    "df_stock = df_stock.merge(df_phan_nganh_cac_cap, how = 'left', left_on='id_lv5', right_on='id').drop(columns=['ETL_date', 'id', 'phan_nganh']).rename(columns={'ten_nganh': 'ten_nganh_lv5'})\n",
    "df_stock = df_stock.fillna('Chưa phân ngành')\n",
    "df_stock[\"ETL_date\"] = str(dt.datetime.now())\n",
    "\n",
    "query = '''if (OBJECT_ID('dim_stock') is not null)\n",
    "begin\n",
    "\tprint('abcd')\n",
    "end\n",
    "else\n",
    "begin\n",
    "\tcreate table dim_stock\n",
    "\t(\n",
    "\t\t[Stock Id] int,\n",
    "\t\t[Ma_ck] varchar(10),\n",
    "        [Ten_doanh_nghiep] nvarchar(100),\n",
    "        [id_lv1] float,\n",
    "        [id_lv2] float,\n",
    "        [id_lv3] float,\n",
    "        [id_lv4] float,\n",
    "        [id_lv5] float,\n",
    "        [ten_nganh_lv1] nvarchar(100),\n",
    "        [ten_nganh_lv2] nvarchar(100),\n",
    "        [ten_nganh_lv3] nvarchar(100),\n",
    "        [ten_nganh_lv4] nvarchar(100),\n",
    "        [ten_nganh_lv5] nvarchar(100),\n",
    "        [ETL_date] varchar(50)\n",
    "\t);\n",
    "end'''\n",
    "cursor.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df_stock.to_csv(f\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_stock.txt\", index=False)\n",
    "with open(\"D:\\\\Tin hoc\\\\Project\\\\Thong ke thi truong\\\\database_file\\\\dim_stock.txt\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    cursor.execute('TRUNCATE TABLE dim_stock')\n",
    "    cursor.executemany(''' INSERT INTO dim_stock Values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''', reader)\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
